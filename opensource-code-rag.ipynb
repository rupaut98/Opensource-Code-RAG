{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9724911,"sourceType":"datasetVersion","datasetId":5950495}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the first 100,000 examples from the 'train' split of the 'python' subset\ndataset = load_dataset(\"code_search_net\", \"python\", split=\"train[:100000]\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T21:25:49.573835Z","iopub.execute_input":"2024-10-28T21:25:49.574682Z","iopub.status.idle":"2024-10-28T21:31:20.024521Z","shell.execute_reply.started":"2024-10-28T21:25:49.574642Z","shell.execute_reply":"2024-10-28T21:31:20.023602Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"code_search_net.py:   0%|          | 0.00/8.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f6154c97fb4bb89aa660a0a373a1de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d149f5f925d4a4fba1cd6ba2ba3daf1"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"python.zip:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99b37b87cc60442f8550034a0a02620d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5363e769f7e64f73b67550934632d0fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5061287d621f455c93be7e8ad00e2b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2d5ff73daf4dfa94a6c76e57b3c80d"}},"metadata":{}}]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:33:51.336109Z","iopub.execute_input":"2024-10-28T21:33:51.336905Z","iopub.status.idle":"2024-10-28T21:33:51.341634Z","shell.execute_reply.started":"2024-10-28T21:33:51.336842Z","shell.execute_reply":"2024-10-28T21:33:51.340760Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n    num_rows: 100000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pandas\n\nimport pandas as pd\n\ninclude_metadata = [\"func_documentation_string\", \"func_code_string\", \"func_name\", \"func_code_url\"]\ndf = pd.DataFrame(dataset)[include_metadata]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:02.486364Z","iopub.execute_input":"2024-10-28T21:34:02.487435Z","iopub.status.idle":"2024-10-28T21:34:48.328674Z","shell.execute_reply.started":"2024-10-28T21:34:02.487381Z","shell.execute_reply":"2024-10-28T21:34:48.327723Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lightly process the func_code_string value. Remove trailing whitespaces and extra lines\nimport re\ndef preprocess_func_code_string(code):\n    code = \"\\n\".join([line.rstrip() for line in code.splitlines()])\n    code = re.sub(r'n\\{2,}', '\\n\\n', code)\n    return code","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:48.331158Z","iopub.execute_input":"2024-10-28T21:34:48.331488Z","iopub.status.idle":"2024-10-28T21:34:48.346524Z","shell.execute_reply.started":"2024-10-28T21:34:48.331453Z","shell.execute_reply":"2024-10-28T21:34:48.345735Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df[\"func_code_string\"].apply(preprocess_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:48.351762Z","iopub.execute_input":"2024-10-28T21:34:48.352087Z","iopub.status.idle":"2024-10-28T21:34:49.355268Z","shell.execute_reply.started":"2024-10-28T21:34:48.352055Z","shell.execute_reply":"2024-10-28T21:34:49.354362Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0        def __msgc_step3_discontinuity_localization(se...\n1        def __multiscale_gc_lo2hi_run(self):  # , pyed...\n2        def __multiscale_gc_hi2lo_run(self):  # , pyed...\n3        def __ordered_values_by_indexes(self, data, in...\n4        def __hi2lo_multiscale_indexes(self, mask, ori...\n                               ...                        \n99995    def close_stream(self):\\n        \"\"\"Close the ...\n99996    def read_response(self):\\n        \"\"\"Read an i...\n99997    def identify(self):\\n        \"\"\"Update client ...\n99998    def auth(self):\\n        \"\"\"Send authorization...\n99999    def subscribe(self, topic, channel):\\n        ...\nName: func_code_string, Length: 100000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:48:03.714585Z","iopub.execute_input":"2024-10-26T03:48:03.715003Z","iopub.status.idle":"2024-10-26T03:48:03.725782Z","shell.execute_reply.started":"2024-10-26T03:48:03.714962Z","shell.execute_reply":"2024-10-26T03:48:03.724809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer(\"mchochlov/codebert-base-cd-ft\", device=device)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:50:57.066188Z","iopub.execute_input":"2024-10-28T21:50:57.066994Z","iopub.status.idle":"2024-10-28T21:51:09.799248Z","shell.execute_reply.started":"2024-10-28T21:50:57.066954Z","shell.execute_reply":"2024-10-28T21:51:09.798287Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings = model.encode(\n    df['func_code_string'].tolist(),\n    convert_to_numpy=True,\n    show_progress_bar=True,\n    device=device,           \n    batch_size=64            \n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:51:09.801411Z","iopub.execute_input":"2024-10-28T21:51:09.802195Z","iopub.status.idle":"2024-10-28T22:03:55.551181Z","shell.execute_reply.started":"2024-10-28T21:51:09.802147Z","shell.execute_reply":"2024-10-28T22:03:55.550256Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1563 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1a79aa3b2d489fb05b96b1f26faa61"}},"metadata":{}}]},{"cell_type":"code","source":"import faiss\nfrom sklearn.preprocessing import normalize\n\n# Normalize embeddings\nembeddings_np = normalize(embeddings, axis=1, norm='l2')\n\n# Build FAISS index\nembedding_dim = embeddings_np.shape[1]\nindex = faiss.IndexFlatIP(embedding_dim)\nindex.add(embeddings_np)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:10:28.163797Z","iopub.execute_input":"2024-10-28T22:10:28.164685Z","iopub.status.idle":"2024-10-28T22:10:28.645162Z","shell.execute_reply.started":"2024-10-28T22:10:28.164642Z","shell.execute_reply":"2024-10-28T22:10:28.644067Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def retrieval_func(query, top_k=5):\n    # Compute query embedding\n    query_embedding = model.encode(query, convert_to_numpy=True)\n    \n    # Normalize query embedding\n    query_embedding_np = normalize(query_embedding.reshape(1, -1), axis=1, norm='l2')\n    \n    # Search in FAISS index\n    distances, indices = index.search(query_embedding_np, top_k)\n    \n    results = []\n    for idx, distance in zip(indices[0], distances[0]):\n        func_name = df.iloc[idx][\"func_name\"]\n        code_snippet = df.iloc[idx][\"func_code_string\"]\n        results.append({\n            \"function_name\": func_name,\n            \"code_snippet\": code_snippet,\n            \"similarity_score\": distance\n        })\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:10:30.709874Z","iopub.execute_input":"2024-10-28T22:10:30.710643Z","iopub.status.idle":"2024-10-28T22:10:30.718033Z","shell.execute_reply.started":"2024-10-28T22:10:30.710599Z","shell.execute_reply":"2024-10-28T22:10:30.716947Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"query = \"how to add numbers\"\n\nresult = retrieval_func(\"how to verify unwanted transactions\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:11:01.932627Z","iopub.execute_input":"2024-10-28T22:11:01.933529Z","iopub.status.idle":"2024-10-28T22:11:02.068062Z","shell.execute_reply.started":"2024-10-28T22:11:01.933487Z","shell.execute_reply":"2024-10-28T22:11:02.067308Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1d75a2a58944b2a4685f65e8bf8d5a"}},"metadata":{}}]},{"cell_type":"code","source":"for i in result:\n    print(i['function_name']+\"\\n\\n\\n\")\n    print(i['code_snippet']+\"\\n\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:11:02.071635Z","iopub.execute_input":"2024-10-28T22:11:02.071950Z","iopub.status.idle":"2024-10-28T22:11:02.076834Z","shell.execute_reply.started":"2024-10-28T22:11:02.071916Z","shell.execute_reply":"2024-10-28T22:11:02.075932Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"cassists\n\n\n\ndef cassists(self,dc,dt,dt2,nodiag=False,memlimit=-1):\n\t\"\"\"Calculates probability of gene i regulating gene j with continuous data assisted method,\n\twith multiple tests, by converting log likelihoods into probabilities per A for all B.\n\tProbabilities are converted from likelihood ratios separately for each A. This gives better\n\tpredictions when the number of secondary targets (dt2) is large. (Check program warnings.)\n\tdc:\tnumpy.ndarray(nt,ns,dtype=ftype(='f4' by default)) Continuous anchor data.\n\t\tEntry dc[i,j] is anchor i's value for sample j.\n\t\tAnchor i is used to infer the probability of gene i -> any other gene.\n\tdt:\tnumpy.ndarray(nt,ns,dtype=ftype(='=f4' by default)) Gene expression data for A\n\t\tEntry dt[i,j] is gene i's expression level for sample j.\n\tdt2:numpy.ndarray(nt2,ns,dtype=ftype(='=f4' by default)) Gene expression data for B.\n\t\tdt2 has the same format as dt, and can be identical with, different from, or a superset of dt.\n\t\tWhen dt2 is a superset of (or identical with) dt, dt2 must be arranged\n\t\tto be identical with dt at its upper submatrix, i.e. dt2[:nt,:]=dt, and\n\t\tset parameter nodiag = 1.\n\tnodiag:\tskip diagonal regulations, i.e. regulation A->B for A=B.\n\t\tThis should be set to True when A is a subset of B and aligned correspondingly.\n\tmemlimit:\tThe approximate memory usage limit in bytes for the library.  For datasets require a larger memory, calculation will be split into smaller chunks. If the memory limit is smaller than minimum required, calculation can fail with an error message. memlimit=0 defaults to unlimited memory usage.\n\tReturn:\tdictionary with following keys:\n\tret:0 iff execution succeeded.\n\tp1:\tnumpy.ndarray(nt,dtype=ftype(='=f4' by default)). Probability for test 1.\n\t\tTest 1 calculates E(A)->A v.s. E(A)  A. The earlier one is preferred.\n\t\tFor nodiag=False, because the function expects significant anchors, p1 always return 1.\n\t\tFor nodiag=True, uses diagonal elements of p2.\n\tp2:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)). Probability for test 2.\n\t\tTest 2 calculates E(A)->A--B with E(A)->B v.s. E(A)->A<-B. The earlier one is preferred.\n\tp3:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)). Probability for test 3.\n\t\tTest 3 calculates E(A)->A--B with E(A)->B v.s. E(A)->A->B. The latter one is preferred.\n\tp4:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)). Probability for test 4.\n\t\tTest 4 calculates E(A)->A--B with E(A)->B v.s. E(A)->A  B. The earlier one is preferred.\n\tp5:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)). Probability for test 5.\n\t\tTest 5 calculates E(A)->A--B with E(A)->B v.s. B<-E(A)->A. The earlier one is preferred.\n\tFor more information on tests, see paper.\n\tftype can be found in auto.py.\n\t\n\tExample: see findr.examples.geuvadis4 (similar format)\n\t\"\"\"\n\treturn _cassists_any(self,dc,dt,dt2,\"pijs_cassist\",nodiag=nodiag,memlimit=memlimit)\n\n\n\nalignment\n\n\n\ndef alignment(layer, decay_ratio=2):\n  \"\"\"Encourage neighboring images to be similar.\n\n  When visualizing the interpolation between two objectives, it's often\n  desireable to encourage analagous boejcts to be drawn in the same position,\n  to make them more comparable.\n\n  This term penalizes L2 distance between neighboring images, as evaluated at\n  layer.\n\n  In general, we find this most effective if used with a paramaterization that\n  shares across the batch. (In fact, that works quite well by iteself, so this\n  function may just be obselete.)\n\n  Args:\n    layer: layer to penalize at.\n    decay_ratio: how much to decay penalty as images move apart in batch.\n\n  Returns:\n    Objective.\n  \"\"\"\n  def inner(T):\n    batch_n = T(layer).get_shape().as_list()[0]\n    arr = T(layer)\n    accum = 0\n    for d in [1, 2, 3, 4]:\n      for i in range(batch_n - d):\n        a, b = i, i+d\n        arr1, arr2 = arr[a], arr[b]\n        accum += tf.reduce_mean((arr1-arr2)**2) / decay_ratio**float(d)\n    return -accum\n  return inner\n\n\n\ngassist\n\n\n\ndef gassist(self,dg,dt,dt2,na=None,nodiag=False,memlimit=-1):\n\t\"\"\"Calculates probability of gene i regulating gene j with genotype data assisted method,\n\twith the recommended combination of multiple tests.\n\tProbabilities are converted from likelihood ratios separately for each A. This gives better\n\tpredictions when the number of secondary targets (dt2) is large. (Check program warnings.)\n\tdg:\tnumpy.ndarray(nt,ns,dtype=gtype(='u1' by default)) Genotype data.\n\t\tEntry dg[i,j] is genotype i's value for sample j.\n\t\tEach value must be among 0,1,...,na.\n\t\tGenotype i must be best (and significant) eQTL of gene i (in dt).\n\tdt:\tnumpy.ndarray(nt,ns,dtype=ftype(='=f4' by default)) Gene expression data for A\n\t\tEntry dt[i,j] is gene i's expression level for sample j.\n\t\tGenotype i (in dg) must be best (and significant) eQTL of gene i.\n\tdt2:numpy.ndarray(nt2,ns,dtype=ftype(='=f4' by default)) Gene expression data for B.\n\t\tdt2 has the same format as dt, and can be identical with, different from, or a superset of dt.\n\t\tWhen dt2 is a superset of (or identical with) dt, dt2 must be arranged\n\t\tto be identical with dt at its upper submatrix, i.e. dt2[:nt,:]=dt, and\n\t\tset parameter nodiag = 1.\n\tna:\tNumber of alleles the species have. It determintes the maximum number of values each genotype can take. When unspecified, it is automatically\n\t\tdetermined as the maximum of dg.\n\tnodiag:\tskip diagonal regulations, i.e. regulation A->B for A=B.\n\t\tThis should be set to True when A is a subset of B and aligned correspondingly.\n\tmemlimit:\tThe approximate memory usage limit in bytes for the library.  For datasets require a larger memory, calculation will be split into smaller chunks. If the memory limit is smaller than minimum required, calculation can fail with an error message. memlimit=0 defaults to unlimited memory usage.\n\tReturn:\tdictionary with following keys:\n\tret:0 iff execution succeeded.\n\tp:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)).\n\t\tProbability function from for recommended combination of multiple tests.\n\tFor more information on tests, see paper.\n\tftype and gtype can be found in auto.py.\n\t\n\tExample: see findr.examples.geuvadis2, findr.examples.geuvadis3\n\t\"\"\"\n\treturn _gassist_any(self,dg,dt,dt2,\"pij_gassist\",na=na,nodiag=nodiag,memlimit=memlimit)\n\n\n\none_greedy\n\n\n\ndef one_greedy(self,dp,namax=None,nimax=None,nomax=None):\n\t\"\"\"Reconstructs a directed acyclic graph according to prior information of edge significance.\n\tThis function first ranks all edges and introduce the most significant one by one, avoiding\n\tthose that would create a loop. Optional constraints on the maximum total number of edges,\n\tthe number of incoming or outgoing edges for every gene can be specified.\n\tdp:\tnumpy.ndarray(nt,nt,dtype=ftype(='f4' by default))\n\t\tPrior information of edge significance levels. Entry dp[i,j] is significance of edge i to j. \n\t\tA larger values indicates the edge's presence is more probable.\n\t\tOne option to obtain the prior information is to use pairwise inference methods in findr.\n\tdt2:numpy.ndarray(nt2,ns,dtype=ftype(='=f4' by default)) Gene expression data for B.\n\t\tdt2 has the same format as dt, and can be identical with, different from, or a superset of dt.\n\t\tWhen dt2 is a superset of (or identical with) dt, dt2 must be arranged\n\t\tto be identical with dt at its upper submatrix, i.e. dt2[:nt,:]=dt, and\n\t\tset parameter nodiag = 1.\n\tnamax:\tConstraint on the maximum total number of edges in the reconstructed network.\n\tnimax:\tConstraint on the maximum number of incoming edges for each node in the reconstructed\n\t\tnetwork.\n\tnomax:\tConstraint on the maximum number of outgoing edges for each node in the reconstructed\n\t\tnetwork.\n\tReturn:\tdictionary with following keys:\n\tret:0 iff execution succeeded.\n\tnet:\tnumpy.ndarray((nt,nt),dtype=bool). The reconstructed direct acyclic graph or network\n\t\tnet[i,j]=True if an edge from i to j exists in the reconstructed network, and False otherwise.\n\tftype and gtype can be found in auto.py.\n\t\n\tExample: see findr.examples.geuvadis7\n\t\"\"\"\n\ttry: from exceptions import ValueError\n\texcept ImportError: pass\n\tif self.lib is None:\n\t\traise ValueError(\"Not initialized.\")\n\timport numpy as np\n\tfrom .auto import ftype_np\n\tfrom .types import isint\n\tif dp.dtype.char!=ftype_np:\n\t\traise ValueError('Wrong input dtype for prior matrix')\n\tif len(dp.shape)!=2:\n\t\traise ValueError('Wrong input shape')\n\tif not (namax is None or isint(namax)):\n\t\traise ValueError('Wrong namax type')\n\tif namax is not None and namax<=0:\n\t\traise ValueError('Input requires namax>0.')\n\tif namax is None:\n\t\tnamax=-1\n\tif not (nimax is None or isint(nimax)):\n\t\traise ValueError('Wrong nimax type')\n\tif nimax is not None and nimax<=0:\n\t\traise ValueError('Input requires nimax>0.')\n\tif nimax is None:\n\t\tnimax=-1\n\tif not (nomax is None or isint(nomax)):\n\t\traise ValueError('Wrong nomax type')\n\tif nomax is not None and nomax<=0:\n\t\traise ValueError('Input requires nomax>0.')\n\tif nomax is None:\n\t\tnomax=-1\n\t\n\tnt=dp.shape[0]\n\tif nt==0:\n\t\traise ValueError('Invalid prior dimension')\n\tif dp.shape[1]!=nt:\n\t\traise ValueError('Wrong input shape')\n\tif np.isnan(dp).sum()>0:\n\t\traise ValueError('NaN found.')\n\tfunc=self.cfunc('netr_one_greedy',rettype='size_t',argtypes=['const MATRIXF*','MATRIXUC*','size_t','size_t','size_t'])\n\td=np.require(np.zeros((nt,nt),dtype='u1'),requirements=['A','C','O','W'])\n\tdpr=np.require(dp,requirements=['A','C','O','W'])\n\tret=func(dpr,d,namax,nimax,nomax)\n\td=d.astype(bool)\n\tret=(ret==0)\n\tans={'ret':ret,'net':d}\n\treturn ans\n\n\n\nab\n\n\n\ndef ab(x):\n\t\"\"\"\nThis method is the big bottleneck of the parallel BCES code. That's the \nreason why I put these calculations in a separate method, in order to \ndistribute this among the cores. In the original BCES method, this is \ninside the main routine.\n\t\nArgument:\n[y1,y1err,y2,y2err,cerr,nsim]\nwhere nsim is the number of bootstrapping trials sent to each core.\n\n:returns: am,bm : the matrixes with slope and intercept where each line corresponds to a bootrap trial and each column maps a different BCES method (ort, y|x etc).\n\nBe very careful and do not use lambda functions when calling this \nmethod and passing it to multiprocessing or ipython.parallel!\nI spent >2 hours figuring out why the code was not working until I\nrealized the reason was the use of lambda functions.\n\t\"\"\"\n\ty1,y1err,y2,y2err,cerr,nsim=x[0],x[1],x[2],x[3],x[4],x[5]\n\t\n\tfor i in range(nsim):\n\t\t[y1sim,y1errsim,y2sim,y2errsim,cerrsim]=bootstrap([y1,y1err,y2,y2err,cerr])\n\n\t\tasim,bsim,errasim,errbsim,covabsim=bces(y1sim,y1errsim,y2sim,y2errsim,cerrsim)\t\n\t\n\t\tif i==0:\n\t\t\t# Initialize the matrixes\n\t\t\tam,bm=asim.copy(),bsim.copy()\n\t\telse: \n\t\t\tam=numpy.vstack((am,asim))\n\t\t\tbm=numpy.vstack((bm,bsim))\n\t\t\n\treturn am,bm\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}