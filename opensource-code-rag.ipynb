{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9724911,"sourceType":"datasetVersion","datasetId":5950495}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the first 100,000 examples from the 'train' split of the 'python' subset\ndataset = load_dataset(\"code_search_net\", \"python\", split=\"train[:100000]\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T21:25:49.573835Z","iopub.execute_input":"2024-10-28T21:25:49.574682Z","iopub.status.idle":"2024-10-28T21:31:20.024521Z","shell.execute_reply.started":"2024-10-28T21:25:49.574642Z","shell.execute_reply":"2024-10-28T21:31:20.023602Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"code_search_net.py:   0%|          | 0.00/8.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f6154c97fb4bb89aa660a0a373a1de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d149f5f925d4a4fba1cd6ba2ba3daf1"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"python.zip:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99b37b87cc60442f8550034a0a02620d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5363e769f7e64f73b67550934632d0fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5061287d621f455c93be7e8ad00e2b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2d5ff73daf4dfa94a6c76e57b3c80d"}},"metadata":{}}]},{"cell_type":"code","source":"dataset[5000]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:11:45.696528Z","iopub.execute_input":"2024-10-28T22:11:45.697435Z","iopub.status.idle":"2024-10-28T22:11:45.705688Z","shell.execute_reply.started":"2024-10-28T22:11:45.697391Z","shell.execute_reply":"2024-10-28T22:11:45.704817Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'repository_name': 'awacha/sastool',\n 'func_path_in_repository': 'sastool/io/credo_saxsctrl/header.py',\n 'func_name': 'Header.date',\n 'whole_func_string': 'def date(self) -> datetime.datetime:\\n        \"\"\"Date of the experiment (start of exposure)\"\"\"\\n        return self._data[\\'Date\\'] - datetime.timedelta(0, float(self.exposuretime), 0)',\n 'language': 'python',\n 'func_code_string': 'def date(self) -> datetime.datetime:\\n        \"\"\"Date of the experiment (start of exposure)\"\"\"\\n        return self._data[\\'Date\\'] - datetime.timedelta(0, float(self.exposuretime), 0)',\n 'func_code_tokens': ['def',\n  'date',\n  '(',\n  'self',\n  ')',\n  '->',\n  'datetime',\n  '.',\n  'datetime',\n  ':',\n  'return',\n  'self',\n  '.',\n  '_data',\n  '[',\n  \"'Date'\",\n  ']',\n  '-',\n  'datetime',\n  '.',\n  'timedelta',\n  '(',\n  '0',\n  ',',\n  'float',\n  '(',\n  'self',\n  '.',\n  'exposuretime',\n  ')',\n  ',',\n  '0',\n  ')'],\n 'func_documentation_string': 'Date of the experiment (start of exposure)',\n 'func_documentation_tokens': ['Date',\n  'of',\n  'the',\n  'experiment',\n  '(',\n  'start',\n  'of',\n  'exposure',\n  ')'],\n 'split_name': 'train',\n 'func_code_url': 'https://github.com/awacha/sastool/blob/deaddfa3002f3f6818697e36139633b7e30427a3/sastool/io/credo_saxsctrl/header.py#L211-L213'}"},"metadata":{}}]},{"cell_type":"code","source":"!pip install pandas\n\nimport pandas as pd\n\ninclude_metadata = [\"func_documentation_string\", \"func_code_string\", \"func_name\", \"func_code_url\"]\ndf = pd.DataFrame(dataset)[include_metadata]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:02.486364Z","iopub.execute_input":"2024-10-28T21:34:02.487435Z","iopub.status.idle":"2024-10-28T21:34:48.328674Z","shell.execute_reply.started":"2024-10-28T21:34:02.487381Z","shell.execute_reply":"2024-10-28T21:34:48.327723Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lightly process the func_code_string value. Remove trailing whitespaces and extra lines\nimport re\ndef preprocess_func_code_string(code):\n    code = \"\\n\".join([line.rstrip() for line in code.splitlines()])\n    code = re.sub(r'n\\{2,}', '\\n\\n', code)\n    return code","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:48.331158Z","iopub.execute_input":"2024-10-28T21:34:48.331488Z","iopub.status.idle":"2024-10-28T21:34:48.346524Z","shell.execute_reply.started":"2024-10-28T21:34:48.331453Z","shell.execute_reply":"2024-10-28T21:34:48.345735Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df[\"func_code_string\"].apply(preprocess_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:34:48.351762Z","iopub.execute_input":"2024-10-28T21:34:48.352087Z","iopub.status.idle":"2024-10-28T21:34:49.355268Z","shell.execute_reply.started":"2024-10-28T21:34:48.352055Z","shell.execute_reply":"2024-10-28T21:34:49.354362Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0        def __msgc_step3_discontinuity_localization(se...\n1        def __multiscale_gc_lo2hi_run(self):  # , pyed...\n2        def __multiscale_gc_hi2lo_run(self):  # , pyed...\n3        def __ordered_values_by_indexes(self, data, in...\n4        def __hi2lo_multiscale_indexes(self, mask, ori...\n                               ...                        \n99995    def close_stream(self):\\n        \"\"\"Close the ...\n99996    def read_response(self):\\n        \"\"\"Read an i...\n99997    def identify(self):\\n        \"\"\"Update client ...\n99998    def auth(self):\\n        \"\"\"Send authorization...\n99999    def subscribe(self, topic, channel):\\n        ...\nName: func_code_string, Length: 100000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:48:03.714585Z","iopub.execute_input":"2024-10-26T03:48:03.715003Z","iopub.status.idle":"2024-10-26T03:48:03.725782Z","shell.execute_reply.started":"2024-10-26T03:48:03.714962Z","shell.execute_reply":"2024-10-26T03:48:03.724809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer(\"mchochlov/codebert-base-cd-ft\", device=device)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:50:57.066188Z","iopub.execute_input":"2024-10-28T21:50:57.066994Z","iopub.status.idle":"2024-10-28T21:51:09.799248Z","shell.execute_reply.started":"2024-10-28T21:50:57.066954Z","shell.execute_reply":"2024-10-28T21:51:09.798287Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings = model.encode(\n    df['func_code_string'].tolist(),\n    convert_to_numpy=True,\n    show_progress_bar=True,\n    device=device,           \n    batch_size=64            \n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:51:09.801411Z","iopub.execute_input":"2024-10-28T21:51:09.802195Z","iopub.status.idle":"2024-10-28T22:03:55.551181Z","shell.execute_reply.started":"2024-10-28T21:51:09.802147Z","shell.execute_reply":"2024-10-28T22:03:55.550256Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1563 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1a79aa3b2d489fb05b96b1f26faa61"}},"metadata":{}}]},{"cell_type":"code","source":"import faiss\nfrom sklearn.preprocessing import normalize\n\n# Normalize embeddings\nembeddings_np = normalize(embeddings, axis=1, norm='l2')\n\n# Build FAISS index\nembedding_dim = embeddings_np.shape[1]\nindex = faiss.IndexFlatIP(embedding_dim)\nindex.add(embeddings_np)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:10:28.163797Z","iopub.execute_input":"2024-10-28T22:10:28.164685Z","iopub.status.idle":"2024-10-28T22:10:28.645162Z","shell.execute_reply.started":"2024-10-28T22:10:28.164642Z","shell.execute_reply":"2024-10-28T22:10:28.644067Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def retrieval_func(query, top_k=5):\n    # Compute query embedding\n    query_embedding = model.encode(query, convert_to_numpy=True)\n    \n    # Normalize query embedding\n    query_embedding_np = normalize(query_embedding.reshape(1, -1), axis=1, norm='l2')\n    \n    # Search in FAISS index\n    distances, indices = index.search(query_embedding_np, top_k)\n    \n    results = []\n    for idx, distance in zip(indices[0], distances[0]):\n        func_name = df.iloc[idx][\"func_name\"]\n        code_snippet = df.iloc[idx][\"func_code_string\"]\n        results.append({\n            \"function_name\": func_name,\n            \"code_snippet\": code_snippet,\n            \"similarity_score\": distance\n        })\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:10:30.709874Z","iopub.execute_input":"2024-10-28T22:10:30.710643Z","iopub.status.idle":"2024-10-28T22:10:30.718033Z","shell.execute_reply.started":"2024-10-28T22:10:30.710599Z","shell.execute_reply":"2024-10-28T22:10:30.716947Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"query = \"Rate of change\"\n\nresult = retrieval_func(query)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:17:35.887912Z","iopub.execute_input":"2024-10-28T22:17:35.888311Z","iopub.status.idle":"2024-10-28T22:17:36.022597Z","shell.execute_reply.started":"2024-10-28T22:17:35.888272Z","shell.execute_reply":"2024-10-28T22:17:36.021889Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e996210a9f664e9e9e76f0a6269337ea"}},"metadata":{}}]},{"cell_type":"code","source":"for i in result:\n    print(i['function_name']+\"\\n\\n\\n\")\n    print(i['code_snippet']+\"\\n\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T22:17:36.024660Z","iopub.execute_input":"2024-10-28T22:17:36.024990Z","iopub.status.idle":"2024-10-28T22:17:36.030088Z","shell.execute_reply.started":"2024-10-28T22:17:36.024957Z","shell.execute_reply":"2024-10-28T22:17:36.029211Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"sine_wave\n\n\n\ndef sine_wave(frequency):\n  \"\"\"Emit a sine wave at the given frequency.\"\"\"\n  xs = tf.reshape(tf.range(_samples(), dtype=tf.float32), [1, _samples(), 1])\n  ts = xs / FLAGS.sample_rate\n  return tf.sin(2 * math.pi * frequency * ts)\n\n\n\nnormalize\n\n\n\ndef normalize(v, axis=None, eps=1e-10):\n  \"\"\"L2 Normalize along specified axes.\"\"\"\n  return v / max(anorm(v, axis=axis, keepdims=True), eps)\n\n\n\n_relu\n\n\n\ndef _relu(x, leakiness=0.0):\n  \"\"\"Relu, with optional leaky support.\"\"\"\n  return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')\n\n\n\nepoch_rates_to_pmf\n\n\n\ndef epoch_rates_to_pmf(problems, epoch_rates=None):\n  \"\"\"Create a probability-mass-function based on relative epoch rates.\n\n  if epoch_rates=None, then we use uniform epoch rates [1.0] * len(problems)\n  i.e. it takes each problem the same time to go through one epoch.\n\n  If epoch_rates is given, then these are the relative numbers of epochs\n  of each problem to go through in a given amount of time.\n\n  Each must have problem.num_training_examples implemented.\n\n  Args:\n    problems: a list of Problem instances.\n    epoch_rates: an optional list of float\n\n  Returns:\n    a list of floating point values.\n  \"\"\"\n  if epoch_rates is None:\n    epoch_rates = [1.0] * len(problems)\n  example_rates = [epoch_rate * p.num_training_examples\n                   for p, epoch_rate in zip(problems, epoch_rates)]\n  return example_rates_to_pmf(example_rates)\n\n\n\nkeep_impute\n\n\n\ndef keep_impute(nkeep, X_train, y_train, X_test, y_test, attr_test, model_generator, metric, trained_model, random_state):\n    \"\"\" The model is revaluated for each test sample with the non-important features set to an imputed value.\n\n    Note that the imputation is done using a multivariate normality assumption on the dataset. This depends on\n    being able to estimate the full data covariance matrix (and inverse) accuractly. So X_train.shape[0] should\n    be significantly bigger than X_train.shape[1].\n    \"\"\"\n\n    X_train, X_test = to_array(X_train, X_test)\n\n    # how many features to mask\n    assert X_train.shape[1] == X_test.shape[1]\n\n    # keep nkeep top features for each test explanation\n    C = np.cov(X_train.T)\n    C += np.eye(C.shape[0]) * 1e-6\n    X_test_tmp = X_test.copy()\n    yp_masked_test = np.zeros(y_test.shape)\n    tie_breaking_noise = const_rand(X_train.shape[1], random_state) * 1e-6\n    mean_vals = X_train.mean(0)\n    for i in range(len(y_test)):\n        if nkeep[i] < X_test.shape[1]:\n            ordering = np.argsort(-attr_test[i,:] + tie_breaking_noise)\n            observe_inds = ordering[:nkeep[i]]\n            impute_inds = ordering[nkeep[i]:]\n            \n            # impute missing data assuming it follows a multivariate normal distribution\n            Coo_inv = np.linalg.inv(C[observe_inds,:][:,observe_inds])\n            Cio = C[impute_inds,:][:,observe_inds]\n            impute = mean_vals[impute_inds] + Cio @ Coo_inv @ (X_test[i, observe_inds] - mean_vals[observe_inds])\n            \n            X_test_tmp[i, impute_inds] = impute\n\n    yp_masked_test = trained_model.predict(X_test_tmp)\n\n    return metric(y_test, yp_masked_test)\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}