{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load only the Python subset from CodeSearchNet\ndataset = load_dataset(\"code_search_net\", \"python\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-26T00:39:46.341183Z","iopub.execute_input":"2024-10-26T00:39:46.341490Z","iopub.status.idle":"2024-10-26T00:39:47.180629Z","shell.execute_reply.started":"2024-10-26T00:39:46.341429Z","shell.execute_reply":"2024-10-26T00:39:47.179699Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = dataset[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T00:43:26.221688Z","iopub.execute_input":"2024-10-26T00:43:26.222436Z","iopub.status.idle":"2024-10-26T00:43:26.227116Z","shell.execute_reply.started":"2024-10-26T00:43:26.222384Z","shell.execute_reply":"2024-10-26T00:43:26.225905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"include_metadata = [\"func_documentation_string\", \"func_code_string\", \"func_name\", \"func_code_url\"]\ndf = pd.DataFrame(dataset)[include_metadata]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T00:55:15.982491Z","iopub.execute_input":"2024-10-26T00:55:15.983416Z","iopub.status.idle":"2024-10-26T00:57:43.897994Z","shell.execute_reply.started":"2024-10-26T00:55:15.983376Z","shell.execute_reply":"2024-10-26T00:57:43.897041Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Lightly process the func_code_string value. Remove trailing whitespaces and extra lines\nimport re\ndef preprocess_func_code_string(code):\n    code = \"\\n\".join([line.rstrip() for line in code.splitlines()])\n    code = re.sub(r'n\\{2,}', '\\n\\n', code)\n    return code","metadata":{"execution":{"iopub.status.busy":"2024-10-26T01:00:12.305373Z","iopub.execute_input":"2024-10-26T01:00:12.306134Z","iopub.status.idle":"2024-10-26T01:00:12.311726Z","shell.execute_reply.started":"2024-10-26T01:00:12.306090Z","shell.execute_reply":"2024-10-26T01:00:12.310575Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df[:5][\"func_code_string\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T00:59:19.036884Z","iopub.execute_input":"2024-10-26T00:59:19.037292Z","iopub.status.idle":"2024-10-26T00:59:19.044708Z","shell.execute_reply.started":"2024-10-26T00:59:19.037255Z","shell.execute_reply":"2024-10-26T00:59:19.043463Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'def __msgc_step3_discontinuity_localization(self):\\n        \"\"\"\\n        Estimate discontinuity in basis of low resolution image segmentation.\\n        :return: discontinuity in low resolution\\n        \"\"\"\\n        import scipy\\n\\n        start = self._start_time\\n        seg = 1 - self.segmentation.astype(np.int8)\\n        self.stats[\"low level object voxels\"] = np.sum(seg)\\n        self.stats[\"low level image voxels\"] = np.prod(seg.shape)\\n        # in seg is now stored low resolution segmentation\\n        # back to normal parameters\\n        # step 2: discontinuity localization\\n        # self.segparams = sparams_hi\\n        seg_border = scipy.ndimage.filters.laplace(seg, mode=\"constant\")\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # logger.debug(str(np.max(seg_border)))\\n        # logger.debug(str(np.min(seg_border)))\\n        seg_border[seg_border != 0] = 1\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # scipy.ndimage.morphology.distance_transform_edt\\n        boundary_dilatation_distance = self.segparams[\"boundary_dilatation_distance\"]\\n        seg = scipy.ndimage.morphology.binary_dilation(\\n            seg_border,\\n            # seg,\\n            np.ones(\\n                [\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                ]\\n            ),\\n        )\\n        if self.keep_temp_properties:\\n            self.temp_msgc_lowres_discontinuity = seg\\n        else:\\n            self.temp_msgc_lowres_discontinuity = None\\n\\n        if self.debug_images:\\n            import sed3\\n\\n            pd = sed3.sed3(seg_border)  # ), contour=seg)\\n            pd.show()\\n            pd = sed3.sed3(seg)  # ), contour=seg)\\n            pd.show()\\n        # segzoom = scipy.ndimage.interpolation.zoom(seg.astype(\\'float\\'), zoom,\\n        #                                                order=0).astype(\\'int8\\')\\n        self.stats[\"t3\"] = time.time() - start\\n        return seg'"},"metadata":{}}]},{"cell_type":"code","source":"df[\"func_code_string\"].apply(preprocess_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T01:00:15.206714Z","iopub.execute_input":"2024-10-26T01:00:15.207702Z","iopub.status.idle":"2024-10-26T01:00:19.408870Z","shell.execute_reply.started":"2024-10-26T01:00:15.207658Z","shell.execute_reply":"2024-10-26T01:00:19.407796Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0         def __msgc_step3_discontinuity_localization(se...\n1         def __multiscale_gc_lo2hi_run(self):  # , pyed...\n2         def __multiscale_gc_hi2lo_run(self):  # , pyed...\n3         def __ordered_values_by_indexes(self, data, in...\n4         def __hi2lo_multiscale_indexes(self, mask, ori...\n                                ...                        \n412173    def load_object(obj) -> object:\\n    \"\"\"Load a...\n412174    def escape_args(cls, *args):\\n        \"\"\"\\n   ...\n412175    def get_page_from_string_or_id(page_string, la...\n412176    def pages_siblings_menu(context, page, url='/'...\n412177    def pages_admin_menu(context, page):\\n    \"\"\"R...\nName: func_code_string, Length: 412178, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[:5][\"func_code_string\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T01:00:22.739480Z","iopub.execute_input":"2024-10-26T01:00:22.740245Z","iopub.status.idle":"2024-10-26T01:00:22.748217Z","shell.execute_reply.started":"2024-10-26T01:00:22.740197Z","shell.execute_reply":"2024-10-26T01:00:22.746904Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'def __msgc_step3_discontinuity_localization(self):\\n        \"\"\"\\n        Estimate discontinuity in basis of low resolution image segmentation.\\n        :return: discontinuity in low resolution\\n        \"\"\"\\n        import scipy\\n\\n        start = self._start_time\\n        seg = 1 - self.segmentation.astype(np.int8)\\n        self.stats[\"low level object voxels\"] = np.sum(seg)\\n        self.stats[\"low level image voxels\"] = np.prod(seg.shape)\\n        # in seg is now stored low resolution segmentation\\n        # back to normal parameters\\n        # step 2: discontinuity localization\\n        # self.segparams = sparams_hi\\n        seg_border = scipy.ndimage.filters.laplace(seg, mode=\"constant\")\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # logger.debug(str(np.max(seg_border)))\\n        # logger.debug(str(np.min(seg_border)))\\n        seg_border[seg_border != 0] = 1\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # scipy.ndimage.morphology.distance_transform_edt\\n        boundary_dilatation_distance = self.segparams[\"boundary_dilatation_distance\"]\\n        seg = scipy.ndimage.morphology.binary_dilation(\\n            seg_border,\\n            # seg,\\n            np.ones(\\n                [\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                ]\\n            ),\\n        )\\n        if self.keep_temp_properties:\\n            self.temp_msgc_lowres_discontinuity = seg\\n        else:\\n            self.temp_msgc_lowres_discontinuity = None\\n\\n        if self.debug_images:\\n            import sed3\\n\\n            pd = sed3.sed3(seg_border)  # ), contour=seg)\\n            pd.show()\\n            pd = sed3.sed3(seg)  # ), contour=seg)\\n            pd.show()\\n        # segzoom = scipy.ndimage.interpolation.zoom(seg.astype(\\'float\\'), zoom,\\n        #                                                order=0).astype(\\'int8\\')\\n        self.stats[\"t3\"] = time.time() - start\\n        return seg'"},"metadata":{}}]},{"cell_type":"code","source":"#loading CodeBERT\n!pip install transformers\n\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\nmodel = AutoModel.from_pretrained(\"microsoft/codebert-base\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T01:03:04.157629Z","iopub.execute_input":"2024-10-26T01:03:04.158085Z","iopub.status.idle":"2024-10-26T01:03:28.423177Z","shell.execute_reply.started":"2024-10-26T01:03:04.158045Z","shell.execute_reply":"2024-10-26T01:03:28.421207Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c04ec473ed7d428c957aa4a781e5482d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b71678b003d4a0cb78e777cbb5a2fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826a7d23430d4643899148815b146f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0af795fd765e4fb8beda7a985c09dfb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dd7e13bce334d46be2c043de4b5a84b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b59641eabb4dfa9c5a050403e5604f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e792dd09bb14b819789b515e34b27c2"}},"metadata":{}}]},{"cell_type":"code","source":"#Tokenizing and appending raw tokens to the dataframe. \ndef tokenize_func_code_string(code):\n    return tokenizer.encode(code, truncation=True, padding=\"max_length\") #for consistent token length and code too long for tokenizer\n\ndf[\"func_code_string_token\"] = df[\"func_code_string\"].apply(tokenize_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T01:08:43.683100Z","iopub.execute_input":"2024-10-26T01:08:43.683842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}