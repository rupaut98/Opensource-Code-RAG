{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9724911,"sourceType":"datasetVersion","datasetId":5950495}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the first 100,000 examples from the 'train' split of the 'python' subset\ndataset = load_dataset(\"code_search_net\", \"python\", split=\"train[:100000]\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-26T03:40:32.465310Z","iopub.execute_input":"2024-10-26T03:40:32.466135Z","iopub.status.idle":"2024-10-26T03:46:00.696579Z","shell.execute_reply.started":"2024-10-26T03:40:32.466091Z","shell.execute_reply":"2024-10-26T03:46:00.695656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available, otherwise use CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:46:03.494007Z","iopub.execute_input":"2024-10-26T03:46:03.494389Z","iopub.status.idle":"2024-10-26T03:46:06.714220Z","shell.execute_reply.started":"2024-10-26T03:46:03.494354Z","shell.execute_reply":"2024-10-26T03:46:06.713358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:46:32.160498Z","iopub.execute_input":"2024-10-26T03:46:32.161381Z","iopub.status.idle":"2024-10-26T03:46:32.166085Z","shell.execute_reply.started":"2024-10-26T03:46:32.161337Z","shell.execute_reply":"2024-10-26T03:46:32.165135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pandas\n\nimport pandas as pd\n\ninclude_metadata = [\"func_documentation_string\", \"func_code_string\", \"func_name\", \"func_code_url\"]\ndf = pd.DataFrame(dataset)[include_metadata]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:46:37.606617Z","iopub.execute_input":"2024-10-26T03:46:37.607483Z","iopub.status.idle":"2024-10-26T03:47:24.914307Z","shell.execute_reply.started":"2024-10-26T03:46:37.607439Z","shell.execute_reply":"2024-10-26T03:47:24.913383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:5]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:47:35.447626Z","iopub.execute_input":"2024-10-26T03:47:35.448141Z","iopub.status.idle":"2024-10-26T03:47:35.464802Z","shell.execute_reply.started":"2024-10-26T03:47:35.448099Z","shell.execute_reply":"2024-10-26T03:47:35.463914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lightly process the func_code_string value. Remove trailing whitespaces and extra lines\nimport re\ndef preprocess_func_code_string(code):\n    code = \"\\n\".join([line.rstrip() for line in code.splitlines()])\n    code = re.sub(r'n\\{2,}', '\\n\\n', code)\n    return code","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:47:42.879077Z","iopub.execute_input":"2024-10-26T03:47:42.879837Z","iopub.status.idle":"2024-10-26T03:47:42.884949Z","shell.execute_reply.started":"2024-10-26T03:47:42.879800Z","shell.execute_reply":"2024-10-26T03:47:42.883775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:5]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:47:48.317606Z","iopub.execute_input":"2024-10-26T03:47:48.318457Z","iopub.status.idle":"2024-10-26T03:47:48.329103Z","shell.execute_reply.started":"2024-10-26T03:47:48.318408Z","shell.execute_reply":"2024-10-26T03:47:48.328135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"func_code_string\"].apply(preprocess_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:47:55.774295Z","iopub.execute_input":"2024-10-26T03:47:55.775079Z","iopub.status.idle":"2024-10-26T03:47:56.771688Z","shell.execute_reply.started":"2024-10-26T03:47:55.775040Z","shell.execute_reply":"2024-10-26T03:47:56.770796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:5]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:48:03.714585Z","iopub.execute_input":"2024-10-26T03:48:03.715003Z","iopub.status.idle":"2024-10-26T03:48:03.725782Z","shell.execute_reply.started":"2024-10-26T03:48:03.714962Z","shell.execute_reply":"2024-10-26T03:48:03.724809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading CodeBERT\n!pip install transformers\n\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\nmodel = AutoModel.from_pretrained(\"microsoft/codebert-base\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:48:06.326758Z","iopub.execute_input":"2024-10-26T03:48:06.327673Z","iopub.status.idle":"2024-10-26T03:48:24.862369Z","shell.execute_reply.started":"2024-10-26T03:48:06.327624Z","shell.execute_reply":"2024-10-26T03:48:24.861516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tokenizing and appending raw tokens to the dataframe. \ndef tokenize_func_code_string(code):\n    return tokenizer.encode(code, truncation=True, padding=\"max_length\") #for consistent token length and code too long for tokenizer\n\ndf[\"func_code_string_token\"] = df[\"func_code_string\"].apply(tokenize_func_code_string)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:48:41.287953Z","iopub.execute_input":"2024-10-26T03:48:41.288512Z","iopub.status.idle":"2024-10-26T03:50:52.288184Z","shell.execute_reply.started":"2024-10-26T03:48:41.288470Z","shell.execute_reply":"2024-10-26T03:50:52.287151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the token ids to tensor for pytorch, models like CodeBERT are built to process data in tensor form. Tensor form can be imagined as an \n#enhanced version of an array that supports operations on both CPU and GPU.\ndef to_tensor(token_ids):\n    return torch.tensor([token_ids]).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:51:09.201744Z","iopub.execute_input":"2024-10-26T03:51:09.202676Z","iopub.status.idle":"2024-10-26T03:51:09.207343Z","shell.execute_reply.started":"2024-10-26T03:51:09.202626Z","shell.execute_reply":"2024-10-26T03:51:09.206377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"input_ids_tensor\"] = df[\"func_code_string_token\"].apply(to_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:51:11.065680Z","iopub.execute_input":"2024-10-26T03:51:11.066087Z","iopub.status.idle":"2024-10-26T03:51:31.278477Z","shell.execute_reply.started":"2024-10-26T03:51:11.066049Z","shell.execute_reply":"2024-10-26T03:51:31.277621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\n# Set device to GPU if available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    model = model.to(device)\nelse:\n    device = torch.device(\"cpu\")\n    print(\"CUDA is not available. Using CPU.\")\n    model = model.to(device)\n\nembeddings = []  # Embeddings list\n\n# Ensure the model is in evaluation mode\nmodel.eval()\n\n# Disable gradient computation for memory efficiency and speed\nwith torch.no_grad():\n    # Wrap the loop in tqdm for a progress bar\n    for tensor in tqdm(df[\"input_ids_tensor\"], desc=\"Processing tensors\"):\n        tensor = tensor.to(device)\n        \n        outputs = model(input_ids=tensor)\n        \n        # Extract CLS token embedding\n        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n        \n        embeddings.append(cls_embedding)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T03:54:29.848546Z","iopub.execute_input":"2024-10-26T03:54:29.849220Z","iopub.status.idle":"2024-10-26T04:25:16.624116Z","shell.execute_reply.started":"2024-10-26T03:54:29.849178Z","shell.execute_reply":"2024-10-26T04:25:16.623083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Load the embeddings array from the saved .npy file\nembeddings = np.load('/kaggle/input/my-unique-embeddings-dataset/embeddings.npy')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:23:48.936248Z","iopub.execute_input":"2024-10-28T21:23:48.936566Z","iopub.status.idle":"2024-10-28T21:23:51.908804Z","shell.execute_reply.started":"2024-10-28T21:23:48.936530Z","shell.execute_reply":"2024-10-28T21:23:51.907876Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install faiss-gpu\n\nimport numpy as np\nfrom sklearn.preprocessing import normalize\nimport faiss\nfrom tqdm import tqdm\n\n# Get the embedding dimension from the first embedding\nembedding_dim = len(embeddings[0])\n\n# Convert embeddings to a NumPy array and ensure it's in float32 format\nembeddings_np = np.array(embeddings, dtype=np.float32)\n\n# Normalize embeddings with progress bar\nprint(\"Normalizing embeddings...\")\nembeddings_np = normalize(embeddings_np, axis=1, norm='l2')\n\n# Ensure embeddings are contiguous in memory\nembeddings_np = np.ascontiguousarray(embeddings_np)\n\n# Initialize FAISS index with inner product (IP) similarity for cosine similarity search\nindex = faiss.IndexFlatIP(embedding_dim)\n\n# Add embeddings to the FAISS index\nprint(\"Adding embeddings to FAISS index...\")\nindex.add(embeddings_np)  # Batch adding to FAISS\n\nprint(f\"No of embeddings indexed: {index.ntotal}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:24:05.800771Z","iopub.execute_input":"2024-10-28T21:24:05.801732Z","iopub.status.idle":"2024-10-28T21:24:22.530982Z","shell.execute_reply.started":"2024-10-28T21:24:05.801680Z","shell.execute_reply":"2024-10-28T21:24:22.529840Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nNormalizing embeddings...\nAdding embeddings to FAISS index...\nNo of embeddings indexed: 100000\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading CodeBERT\n!pip install transformers\n\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\nmodel = AutoModel.from_pretrained(\"microsoft/codebert-base\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:24:22.532725Z","iopub.execute_input":"2024-10-28T21:24:22.533147Z","iopub.status.idle":"2024-10-28T21:24:43.047357Z","shell.execute_reply.started":"2024-10-28T21:24:22.533114Z","shell.execute_reply":"2024-10-28T21:24:43.046393Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c67a2a07e54370aa0939fdfb73fcbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db48e17f24a4d5ca340ea4005296bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffa67459ef0f4b34b32708f3fbd4c40a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb89237f2ee549aaaac7a3dee774a8a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac61ea30f3004fbe9e8579682701f2e7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575c8ad2167e44fdbb77791a5ac0473d"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available, otherwise use CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T21:24:43.049347Z","iopub.execute_input":"2024-10-28T21:24:43.050006Z","iopub.status.idle":"2024-10-28T21:24:43.454338Z","shell.execute_reply.started":"2024-10-28T21:24:43.049958Z","shell.execute_reply":"2024-10-28T21:24:43.453432Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\ndef retrieval_func(query, top_k=5):\n    query_tokens = tokenizer.encode(query, truncation=True, padding='max_length')\n    query_tensor = torch.tensor([query_tokens]).to(device)\n    \n    with torch.no_grad():\n        query_embedding = model(query_tensor).last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n        \n    query_embedding_np = normalize(query_embedding.reshape(1, -1), axis=1, norm='l2')\n        \n    distances, indices = index.search(query_embedding_np, top_k)\n    \n    results = []\n    \n    for idx, distance in zip(indices[0], distances[0]):\n        func_name = df.iloc[idx][\"func_name\"]\n        code_snippet = df.iloc[idx][\"func_code_string\"]\n        \n        results.append({\n            \"function_name\": func_name,\n            \"code_snippet\": code_snippet,\n            \"similarity_score\": distance\n        })\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-10-27T02:47:15.299247Z","iopub.execute_input":"2024-10-27T02:47:15.299861Z","iopub.status.idle":"2024-10-27T02:47:15.313139Z","shell.execute_reply.started":"2024-10-27T02:47:15.299800Z","shell.execute_reply":"2024-10-27T02:47:15.311462Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"query = \"how to add two numbers\"\n\nresult = retrieval_func(\"how to verify unwanted transactions\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:31:24.784624Z","iopub.status.idle":"2024-10-28T20:31:24.785033Z","shell.execute_reply.started":"2024-10-28T20:31:24.784812Z","shell.execute_reply":"2024-10-28T20:31:24.784831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}